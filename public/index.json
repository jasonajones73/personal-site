[{"authors":null,"categories":null,"content":"\r\r\r\r\r\rThe Boring Bits - Hidden But Viewable\rlibrary(tidyverse)\rlibrary(lubridate)\rlibrary(tidytext)\rlibrary(DT)\rtweets \u0026lt;- read_rds(\u0026quot;data/tweets.rds\u0026quot;) %\u0026gt;%\ras_tibble()\rf \u0026lt;- function(time) {\rx \u0026lt;- time\rhour(x) \u0026lt;- hour(x)-4\rreturn(x)\r}\r\n\r24 Hours of Tweets\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rmutate(created_at = floor_date(created_at, unit = \u0026quot;hour\u0026quot;)) %\u0026gt;%\rmutate(created_at = f(created_at)) %\u0026gt;%\rgroup_by(created_at) %\u0026gt;%\rsummarise(tweet_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rarrange(created_at) %\u0026gt;%\rmutate(running_total = cumsum(tweet_count)) %\u0026gt;%\rtop_n(24, running_total) %\u0026gt;%\rggplot(aes(created_at, running_total)) +\rgeom_col(fill = \u0026quot;#112E51\u0026quot;) +\rgeom_label(aes(label = scales::comma(running_total)), nudge_y = -50, size = 2) +\rscale_y_continuous(labels = scales::comma_format()) +\rlabs(title = \u0026quot;New Tweets: #ELGL19\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.background = element_blank(),\rpanel.grid.major.y = element_line(color = \u0026quot;light grey\u0026quot;))\r\n\rRetweets Are Tweets Too\rtweets %\u0026gt;%\rfilter(is_retweet == TRUE) %\u0026gt;%\rmutate(created_at = floor_date(created_at, unit = \u0026quot;hour\u0026quot;)) %\u0026gt;%\rmutate(created_at = f(created_at)) %\u0026gt;%\rgroup_by(created_at) %\u0026gt;%\rsummarise(tweet_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rarrange(created_at) %\u0026gt;%\rmutate(running_total = cumsum(tweet_count)) %\u0026gt;%\rtop_n(24, running_total) %\u0026gt;%\rggplot(aes(created_at, running_total)) +\rgeom_col(fill = \u0026quot;#FF7043\u0026quot;) +\rgeom_label(aes(label = scales::comma(running_total)), nudge_y = -50, size = 2) +\rscale_y_continuous(labels = scales::comma_format()) +\rlabs(title = \u0026quot;Retweets: #ELGL19\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.background = element_blank(),\rpanel.grid.major.y = element_line(color = \u0026quot;light grey\u0026quot;))\r\n\rBiggest Fans\rMost Original Tweets\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rgroup_by(screen_name) %\u0026gt;%\rsummarise(tweets = n()) %\u0026gt;%\rarrange(desc(tweets)) %\u0026gt;%\rtop_n(100, tweets) %\u0026gt;%\rdatatable(colnames = c(\u0026quot;Twitter ID\u0026quot;, \u0026quot;Tweet Count\u0026quot;))\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\"],[\"kwyatt23\",\"kowyatt\",\"TheBaconDiaries\",\"acornsandnuts\",\"RealMaggieJones\",\"benkittelson56\",\"JBStephens1\",\"Josh_Edwards11\",\"kimstric\",\"77ccampbell\",\"BarkmanSusan\",\"libraryhillary\",\"BabitsKnopeful\",\"novalsi\",\"JanesAlisha\",\"ayshmonroe\",\"ELGL50\",\"Brandoncito27\",\"InfoSysNic\",\"MyPublicTweeter\",\"SavageLaura\",\"JenWCasey\",\"marcemars\",\"sarahemoss\",\"brendanbabb\",\"kittlent\",\"patrickm02L\",\"brent4cities\",\"Joedoespolitics\",\"BuckleyRae\",\"danwein\",\"matt_ygr\",\"OD_Louise\",\"NZRatkai\",\"BloombergCities\",\"btmurphy88\",\"HannahROsborne\",\"myfriendemily\",\"ryanindurham\",\"ShannonAClark8\",\"1stLadyOfWater\",\"anthonysanti\",\"dinberga07\",\"islandellis\",\"Jinjiloo\",\"JTGreiner\",\"SarahKCMO\",\"dlgoldberg\",\"GovLovePodcast\",\"MissEdwardsCLT\",\"StephAWade\",\"ZachNavin\",\"Alma_LBC\",\"AmandaDaflos\",\"AquaTanner\",\"darbomb_\",\"eslangston\",\"Greg_James_\",\"lj_maze\",\"nickintosh\",\"nrc_inc\",\"roger_keren\",\"Shannon24404768\",\"_ResourceX\",\"Angelica_Online\",\"AnniaAleman\",\"assaffrances\",\"CFEfund\",\"dawnbvaughan\",\"JasonReisdorfer\",\"Kaci3785\",\"KelseyN_Parker\",\"larrymattsonian\",\"ltayara1\",\"marisskat\",\"mattmckirahan\",\"newbopke\",\"Public_Input\",\"rngrill\",\"TheDavidFinley\",\"Urbanagami\",\"CarlyLorentz\",\"clearpointstrat\",\"dkleading\",\"egibsonplan\",\"ELGLSconnie\",\"JennyLovsGov\",\"KateBender5\",\"MitchFosterMI\",\"mskibbe\",\"packpridejones\",\"RachelLocke15\",\"TheMarshMethod\",\"viewpointcloud\",\"aaronkfoley\",\"APLiowa\",\"Baltimoreiteam\",\"BoriCubAna\",\"CALELGL\",\"DHedglin\",\"emilyrfultz\",\"FranciePalmer\",\"ghostofliteracy\",\"GMeadowCougar\",\"jmintzCFE\",\"KimShiggy\",\"localgovlaura\",\"luciddreamvr\",\"mdhartleib\",\"MegMcGurk\",\"MichaelDwrites\",\"MountainELGL\",\"mysidewalkHQ\",\"PatMadej\",\"PaulaKwan\",\"pbassi\",\"Rachaelmarieb\",\"RafaelBaptista5\",\"RandomAndal\",\"Sarasti\",\"snapsbyc\",\"TerranceDeShaun\",\"TigardOR\",\"TulsaTransport\"],[134,97,76,54,54,41,37,35,34,32,32,26,24,24,23,20,20,18,18,17,16,15,15,15,14,13,13,12,12,11,10,10,10,9,8,8,8,8,8,8,7,7,7,7,7,7,7,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]],\"container\":\"\\n \\n \\n  \\n Twitter ID\\n Tweet Count\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\rCheering Section\rMost Retweets\rtweets %\u0026gt;%\rfilter(is_retweet == TRUE) %\u0026gt;%\rgroup_by(screen_name) %\u0026gt;%\rsummarise(tweets = n()) %\u0026gt;%\rarrange(desc(tweets)) %\u0026gt;%\rtop_n(100, tweets) %\u0026gt;%\rdatatable(colnames = c(\u0026quot;Twitter ID\u0026quot;, \u0026quot;Retweet Count\u0026quot;))\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\"],[\"ELGL50\",\"SEELGL\",\"77ccampbell\",\"MountainELGL\",\"NWELGL\",\"kowyatt\",\"danwein\",\"acornsandnuts\",\"CALELGL\",\"SWELGL\",\"MidwestELGL\",\"JBStephens1\",\"NEELGL\",\"benkittelson56\",\"ELGLJobs\",\"GovLovePodcast\",\"ELGLSconnie\",\"BarkmanSusan\",\"OhioELGL\",\"_ResourceX\",\"Angelica_Online\",\"libraryhillary\",\"RealMaggieJones\",\"dinberga07\",\"kimstric\",\"SavageLaura\",\"marisskat\",\"CityHallSelfie\",\"enfabian\",\"kwyatt23\",\"MitchFosterMI\",\"novalsi\",\"AquaTanner\",\"ChuckManningSr1\",\"InfoSysNic\",\"Josh_Edwards11\",\"nrc_inc\",\"CFEfund\",\"chrisfabianPBB\",\"sarahemoss\",\"Alma_LBC\",\"BloombergCities\",\"MichaelDwrites\",\"brendanbabb\",\"egibsonplan\",\"matt_ygr\",\"MyPublicTweeter\",\"OD_Louise\",\"TheBaconDiaries\",\"aLocalNow\",\"DamemaMann\",\"hanaschank\",\"HannahROsborne\",\"StephAWade\",\"1stLadyOfWater\",\"AmandaDaflos\",\"dawnbvaughan\",\"PaulaKwan\",\"TheMarshMethod\",\"anthonysanti\",\"JenWCasey\",\"JRTowery\",\"KelseyN_Parker\",\"rolandpersaud\",\"SmartCitiesFeed\",\"ayshmonroe\",\"brent4cities\",\"Joedoespolitics\",\"kjappel\",\"MegMcGurk\",\"MissEdwardsCLT\",\"myfriendemily\",\"CallunaAilish\",\"CroskeyChaparro\",\"emilyrfultz\",\"Greg_James_\",\"JenDellaValle\",\"larrymattsonian\",\"mskibbe\",\"patrickm02L\",\"PaulTheUrbanist\",\"aaronkfoley\",\"AndyKuhn740\",\"AnniaAleman\",\"btmurphy88\",\"clearpointstrat\",\"CommDevSoc\",\"islandellis\",\"JasonReisdorfer\",\"JTGreiner\",\"KatieVPoulsen\",\"KimShiggy\",\"LAinnovates\",\"lightifyco1\",\"loribush\",\"MadisonThesing\",\"packpridejones\",\"PatMadej\",\"Public_Input\",\"Shannon24404768\",\"TigardOR\",\"TJCOGnc\"],[243,125,75,67,58,56,51,45,38,37,36,34,33,32,32,32,31,30,29,27,27,26,24,18,18,18,17,16,16,16,16,16,12,12,11,11,11,10,10,10,9,9,9,8,8,8,8,8,8,7,7,7,7,7,6,6,6,6,6,5,5,5,5,5,5,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]],\"container\":\"\\n \\n \\n  \\n Twitter ID\\n Retweet Count\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\rEnough Already!\rTop Average Tweet Length\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rgroup_by(screen_name) %\u0026gt;%\rsummarise(avg_length = mean(display_text_width)) %\u0026gt;%\rtop_n(15, avg_length) %\u0026gt;%\rggplot(aes(reorder(screen_name, avg_length), avg_length)) +\rgeom_col(fill = \u0026quot;#0095A8\u0026quot;) +\rcoord_flip() +\rlabs(title = \u0026quot;Average Tweet Length\u0026quot;,\rsubtitle = \u0026quot;Top 15\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.background = element_blank(),\rpanel.grid.major.x = element_line(color = \u0026quot;light grey\u0026quot;))\r\n\rShort and Sweet\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rgroup_by(screen_name) %\u0026gt;%\rsummarise(avg_length = mean(display_text_width)) %\u0026gt;%\rtop_n(-15, avg_length) %\u0026gt;%\rggplot(aes(reorder(screen_name, desc(avg_length)), avg_length)) +\rgeom_col(fill = \u0026quot;#0095A8\u0026quot;) +\rcoord_flip() +\rlabs(title = \u0026quot;Average Tweet Length\u0026quot;,\rsubtitle = \u0026quot;Lowest 15\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.background = element_blank(),\rpanel.grid.major.x = element_line(color = \u0026quot;light grey\u0026quot;))\r\n\r\rPopular Kids\rWho gets the most replies?\rtweets %\u0026gt;%\rfilter(is.na(reply_to_screen_name) != TRUE) %\u0026gt;%\rgroup_by(reply_to_screen_name) %\u0026gt;%\rsummarise(tweets = n()) %\u0026gt;%\rarrange(desc(tweets)) %\u0026gt;%\rtop_n(100, tweets) %\u0026gt;%\rdatatable(colnames = c(\u0026quot;Twitter ID\u0026quot;, \u0026quot;Reply Count\u0026quot;))\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\"],[\"kwyatt23\",\"Josh_Edwards11\",\"acornsandnuts\",\"TheBaconDiaries\",\"BarkmanSusan\",\"kowyatt\",\"novalsi\",\"marcemars\",\"benkittelson56\",\"ELGL50\",\"hanaschank\",\"libraryhillary\",\"1stLadyOfWater\",\"BabitsKnopeful\",\"CityofDurhamNC\",\"patrickm02L\",\"RealMaggieJones\",\"ayshmonroe\",\"brent4cities\",\"dawnbvaughan\",\"eslangston\",\"KendraHwa\",\"matt_ygr\",\"mskibbe\",\"SavageLaura\",\"SteveCallaway2\",\"77ccampbell\",\"Alma_LBC\",\"brendanbabb\",\"CarlyLorentz\",\"dinberga07\",\"DKTangeman\",\"emilymedmonds\",\"HannahLebovits\",\"Joedoespolitics\",\"KelseyN_Parker\",\"myfriendemily\",\"NZRatkai\",\"packpridejones\",\"PatMadej\",\"sarahemoss\",\"stevefordurham\",\"TheMarshMethod\",\"ZachNavin\",\"2arinkorpool\",\"aaronkfoley\",\"AdriaF\",\"AmandaDaflos\",\"Angelica_Online\",\"AnniaAleman\",\"assaffrances\",\"BloombergCities\",\"cassiejoaz\",\"CityofDetroit\",\"CtrPubSafExc\",\"DarGreen91\",\"Durham_iteam\",\"DurhamCounty\",\"dwohlbs\",\"emergingissues\",\"GMeadowCougar\",\"GovLovePodcast\",\"hazelsarahmarie\",\"IGotCharts\",\"Indy_CIO\",\"JasonReisdorfer\",\"JBStephens1\",\"JenWCasey\",\"JRTowery\",\"Kaci3785\",\"katequeram\",\"kim_hodo\",\"laceybeaty\",\"LibbyBretthauer\",\"lydialavelle\",\"MadisonThesing\",\"nickintosh\",\"nrc_inc\",\"PaulaKwan\",\"Public_Input\",\"RafaelBaptista5\",\"rngrill\",\"RobSturns\",\"roger_keren\",\"samedelstein\",\"SarahKCMO\",\"sereniah\",\"snapsbyc\",\"sog_ced\",\"terrycyates\",\"TheHoboBoss\",\"Urbanagami\"],[21,18,17,13,12,11,8,7,6,6,6,6,5,5,4,4,4,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],\"container\":\"\\n \\n \\n  \\n Twitter ID\\n Reply Count\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\riPhone or Android?\rTwitter tool of choice\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rgroup_by(source) %\u0026gt;%\rsummarise(Count = n()) %\u0026gt;%\rarrange(desc(Count)) %\u0026gt;%\rtop_n(100, Count) %\u0026gt;%\rdatatable()\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"],[\"Twitter for iPhone\",\"Twitter for Android\",\"Twitter Web Client\",\"Twitter Web App\",\"Twitter for iPad\",\"Instagram\",\"HubSpot\",\"IFTTT\",\"LinkedIn\",\"Sprout Social\",\"Hootsuite Inc.\",\"NLP Testing Bott\",\"TweetDeck\"],[866,353,99,71,12,7,4,2,2,2,1,1,1]],\"container\":\"\\n \\n \\n  \\n source\\n Count\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\rStealing Thunder?\rRetweet has more favorites than original tweet\rtweets %\u0026gt;%\rfilter(favorite_count \u0026lt; retweet_favorite_count) %\u0026gt;%\rgroup_by(screen_name) %\u0026gt;%\rsummarise(thunder_stolen = n()) %\u0026gt;%\rarrange(desc(thunder_stolen)) %\u0026gt;%\rtop_n(100, thunder_stolen) %\u0026gt;%\rdatatable(colnames = c(\u0026quot;Screen Name\u0026quot;, \u0026quot;Count Of Thunder Steals\u0026quot;))\r\r{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\"],[\"ELGL50\",\"SEELGL\",\"77ccampbell\",\"MountainELGL\",\"NWELGL\",\"kowyatt\",\"danwein\",\"acornsandnuts\",\"CALELGL\",\"MidwestELGL\",\"JBStephens1\",\"SWELGL\",\"NEELGL\",\"benkittelson56\",\"ELGLJobs\",\"ELGLSconnie\",\"GovLovePodcast\",\"BarkmanSusan\",\"OhioELGL\",\"_ResourceX\",\"Angelica_Online\",\"libraryhillary\",\"RealMaggieJones\",\"dinberga07\",\"kimstric\",\"SavageLaura\",\"marisskat\",\"CityHallSelfie\",\"enfabian\",\"kwyatt23\",\"MitchFosterMI\",\"novalsi\",\"AquaTanner\",\"ChuckManningSr1\",\"InfoSysNic\",\"Josh_Edwards11\",\"nrc_inc\",\"chrisfabianPBB\",\"sarahemoss\",\"Alma_LBC\",\"BloombergCities\",\"MichaelDwrites\",\"brendanbabb\",\"CFEfund\",\"egibsonplan\",\"matt_ygr\",\"MyPublicTweeter\",\"OD_Louise\",\"TheBaconDiaries\",\"aLocalNow\",\"DamemaMann\",\"hanaschank\",\"HannahROsborne\",\"StephAWade\",\"1stLadyOfWater\",\"AmandaDaflos\",\"PaulaKwan\",\"TheMarshMethod\",\"anthonysanti\",\"dawnbvaughan\",\"JenWCasey\",\"JRTowery\",\"KelseyN_Parker\",\"rolandpersaud\",\"SmartCitiesFeed\",\"ayshmonroe\",\"brent4cities\",\"Joedoespolitics\",\"kjappel\",\"MegMcGurk\",\"MissEdwardsCLT\",\"myfriendemily\",\"CallunaAilish\",\"CroskeyChaparro\",\"emilyrfultz\",\"Greg_James_\",\"JenDellaValle\",\"larrymattsonian\",\"mskibbe\",\"patrickm02L\",\"PaulTheUrbanist\",\"aaronkfoley\",\"AndyKuhn740\",\"AnniaAleman\",\"btmurphy88\",\"clearpointstrat\",\"CommDevSoc\",\"islandellis\",\"JasonReisdorfer\",\"JTGreiner\",\"KatieVPoulsen\",\"KimShiggy\",\"LAinnovates\",\"lightifyco1\",\"loribush\",\"MadisonThesing\",\"packpridejones\",\"PatMadej\",\"Public_Input\",\"Shannon24404768\",\"TigardOR\",\"TJCOGnc\"],[238,121,75,65,57,56,51,45,37,36,34,34,33,31,31,31,31,30,29,27,27,25,24,18,18,18,17,16,16,16,16,16,12,12,11,11,11,10,10,9,9,9,8,8,8,8,8,8,8,7,7,7,7,7,6,6,6,6,5,5,5,5,5,5,5,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]],\"container\":\"\\n \\n \\n  \\n Screen Name\\n Count Of Thunder Steals\\n \\n \\n\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\n\r\rLanguage Is Important\rScoring Tweets by Language Sentiment\rtweets %\u0026gt;%\rfilter(created_at \u0026gt; as.POSIXct(\u0026quot;2019-05-15 23:59:59\u0026quot;)) %\u0026gt;%\rmutate(index = row_number()) %\u0026gt;%\runnest_tokens(\u0026quot;word\u0026quot;, text) %\u0026gt;%\rselect(index, created_at, screen_name, word) %\u0026gt;%\ranti_join(stop_words) %\u0026gt;%\rmutate(created_at = floor_date(created_at, unit = \u0026quot;hour\u0026quot;)) %\u0026gt;%\rmutate(created_at = f(created_at)) %\u0026gt;%\rinner_join(get_sentiments(lexicon = \u0026quot;afinn\u0026quot;)) %\u0026gt;%\rgroup_by(created_at) %\u0026gt;%\rsummarise(score = sum(score)) %\u0026gt;%\rungroup() %\u0026gt;%\rarrange(created_at) %\u0026gt;%\rmutate(sent_flow = cumsum(score)) %\u0026gt;%\rggplot(aes(created_at, sent_flow)) +\rgeom_line() +\rgeom_point(color = \u0026quot;#FF7043\u0026quot;, size = 3) +\rscale_y_continuous(labels = scales::comma_format()) +\rlabs(title = \u0026quot;#ELGL19: Twitter Cumulative Sentiment\u0026quot;,\rsubtitle = \u0026quot;Y\u0026#39;all Some Positive People!\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.background = element_blank(),\rpanel.grid.major.y = element_line(color = \u0026quot;light grey\u0026quot;))\r\n\rMost Used Words\rsentiment \u0026lt;- tweets %\u0026gt;%\rfilter(created_at \u0026gt; as.POSIXct(\u0026quot;2019-05-15 23:59:59\u0026quot;)) %\u0026gt;%\rmutate(index = row_number()) %\u0026gt;%\runnest_tokens(\u0026quot;word\u0026quot;, text) %\u0026gt;%\rselect(index, created_at, screen_name, word) %\u0026gt;%\ranti_join(stop_words) %\u0026gt;%\rmutate(created_at = floor_date(created_at, unit = \u0026quot;hour\u0026quot;)) %\u0026gt;%\rmutate(created_at = f(created_at)) %\u0026gt;%\rinner_join(get_sentiments(lexicon = \u0026quot;bing\u0026quot;)) %\u0026gt;%\rgroup_by(word) %\u0026gt;%\rsummarise(word_count = n()) %\u0026gt;%\rungroup()\rwordcloud::wordcloud(sentiment$word, sentiment$word_count, colors = c(\u0026quot;#0095A8\u0026quot;,\r\u0026quot;#112E51\u0026quot;,\r\u0026quot;#FF7043\u0026quot;))\r\n\r\rWant To Play With The Data Too?\r\rTweet Data CSV\rTweet Data JSON\rTweet Data RDS\r\r\n\r","date":1558732380,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558732380,"objectID":"3ee3a31d7304ff07485cd0ac3a676372","permalink":"/post/2019-05-24-elgl-twitter/","publishdate":"2019-05-24T21:13:00Z","relpermalink":"/post/2019-05-24-elgl-twitter/","section":"post","summary":"The Boring Bits - Hidden But Viewable\rlibrary(tidyverse)\rlibrary(lubridate)\rlibrary(tidytext)\rlibrary(DT)\rtweets \u0026lt;- read_rds(\u0026quot;data/tweets.rds\u0026quot;) %\u0026gt;%\ras_tibble()\rf \u0026lt;- function(time) {\rx \u0026lt;- time\rhour(x) \u0026lt;- hour(x)-4\rreturn(x)\r}\r\n\r24 Hours of Tweets\rtweets %\u0026gt;%\rfilter(is_retweet == FALSE) %\u0026gt;%\rmutate(created_at = floor_date(created_at, unit = \u0026quot;hour\u0026quot;)) %\u0026gt;%\rmutate(created_at = f(created_at)) %\u0026gt;%\rgroup_by(created_at) %\u0026gt;%\rsummarise(tweet_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rarrange(created_at) %\u0026gt;%\rmutate(running_total = cumsum(tweet_count)) %\u0026gt;%\rtop_n(24, running_total) %\u0026gt;%\rggplot(aes(created_at, running_total)) +\rgeom_col(fill = \u0026quot;#112E51\u0026quot;) +\rgeom_label(aes(label = scales::comma(running_total)), nudge_y = -50, size = 2) +\rscale_y_continuous(labels = scales::comma_format()) +\rlabs(title = \u0026quot;New Tweets: #ELGL19\u0026quot;,\rcaption = \u0026quot;Author: Jason Jones, @packpridejones\u0026quot;,\rx = NULL, y = NULL) +\rtheme(panel.","tags":null,"title":"#ELGL19 On Twitter: A Brief Synthesis","type":"post"},{"authors":null,"categories":null,"content":"\r\rWelcome to the wonderful world of R-Spatial! I really enjoy playing around with spatial data in R and for some reason find it much easier than ArcGIS (#sorrynotsorry Esri). Please keep in mind, as with everything I do in R, I am self taught and rely heavily on publicly available resources. My way of doing things may not always be the best or perfect, it is just how I was able to make sense of it.\nOne of the beautiful things about R is that there are many ways to get to your destination (in most cases). If you stumble across something in my code that is just wrong, could be way more efficient, and/or makes you cry into your cereal - please let me know! You definitely won’t hurt my feelings. I just want to get better!\nIn this post I am going to walk through some things that I have found myself doing regularly. A majority of the data I come across does not have a spatial component to it already or may not be associated with the particular geography that I need. Hopefully, I can demonstrate for you one approach to working through this in R.\nThe flow of this generally should be:\nPull down data with coordinates\rPull down polygon data\rVerify overlap and matching projections\rCombine points and polygons\rMap aggressively\rHuzzah!\r\rLoad Packages\rWe will start by doing the obvious and loading our packages. You may notice me references some packages this way: cowplot::plot_grid(). That just means that I opted not to load the entire package since I may only be using it one time. You may already know that but some of may not so just bear with me.\nlibrary(sf)\rlibrary(tidyverse)\rlibrary(sp)\r\rCreate Custom Theme\rHere, I am quickly defining some thematic elements for my plots so I don’t have to repeat them. I really need to get better about doing this!\njason_theme \u0026lt;- theme(plot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\r\rDownload Police Incidents\rI use the GeoJSON link on the Raleigh Open Data Portal to download police incidents.\n\rpolice_incidents \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/24c0b37fa9bb4e16ba8bcaa7e806c615_0.geojson\u0026quot;)\r\rFilter Missing Coordinates\rQuickly filter records that are missing coordinates.\npolice_incidents \u0026lt;- police_incidents %\u0026gt;%\rfilter(is.na(latitude) != TRUE)\r\rTest Plot\rLet’s just give it a try to make sure everything is working as intended. I am using base R here simply because it is faster.\nplot(police_incidents$geometry)\r\rDownload Wake Census Tracts\r\rwake_tracts \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/21d4ff44498a4007beefdcbde6fcd2a9_0.geojson\u0026quot;)\r\rTest Plot\rAnother base R test plot just to be sure.\nplot(wake_tracts$geometry)\r\rBasic Density Plot\rGreat! Looks like everything is working as intended. Before I dive in to combining data, I want to show you a couple cool things you can do with these items in isolation.\nCreate Tibble for Density Plotting\rIn this first step, I am using st_coordinates() to strip the coordinates out of my police incidents simple feature object. I am then storing those coordinates as a tibble that I can pass to my plot. This is a necessary step for the density plotting that I want to do.\ndens_dat \u0026lt;- police_incidents %\u0026gt;%\rst_coordinates() %\u0026gt;%\ras_tibble()\r\rDensity Map\rI have everything I need now to do a quick map of the density of police incident points. Notice I use ..level.. to access that statistic computed by the call to stat_density_2d. You can read more about what is happening behind the scenes here. Gotta love the R community!\ndens_dat %\u0026gt;%\rggplot() +\rgeom_sf(data = wake_tracts, color = \u0026quot;grey\u0026quot;, fill = NA) +\rstat_density_2d(aes(X, Y, fill = ..level..), geom = \u0026quot;polygon\u0026quot;, alpha = 0.6) +\rscale_fill_viridis_c(\u0026quot;Density\u0026quot;, option = \u0026quot;magma\u0026quot;, direction = -1) +\rjason_theme\r\rHexbin Map\rMaybe that doesn’t do it for you. Well strap yourself in for a hexbin map!\ndens_dat %\u0026gt;%\rggplot() +\rgeom_sf(data = wake_tracts, color = \u0026quot;grey\u0026quot;, fill = NA) +\rgeom_hex(aes(X, Y), alpha = 0.6) +\rscale_fill_viridis_c(\u0026quot;Count\u0026quot;, option = \u0026quot;magma\u0026quot;, direction = -1) +\rjason_theme\r\r\rA Step Further\rThose are a couple of quick maps you can generate with the data in isolation. Let’s take it a step further and see what we can do if we combine the data.\nConvert to Spatial Objects\rThe first thing I need to do is convert both of my simple feature objects to Spatial*DataFrame.\npolice_spatial \u0026lt;- police_incidents %\u0026gt;%\rfilter(is.na(latitude) != TRUE) %\u0026gt;%\ras_Spatial()\rwake_spatial \u0026lt;- wake_tracts %\u0026gt;%\ras_Spatial()\r\rCheck Projections\rNow I need to verify that my projections (Coordinated Reference Systems (CRS)) are matching.\nral_crs \u0026lt;- proj4string(police_spatial)\rwake_crs \u0026lt;- proj4string(wake_spatial)\rprint(ral_crs == wake_crs)\r## [1] TRUE\r\rCreate Overlay\rTrue means we are good to go! Now I can use over() to overlay my police incident points and Wake County census tracts. It will return the census tract attributes that are associated with each police incident record. After I perform the overlay, I am simply binding everything together.\noverlay \u0026lt;- over(police_spatial, wake_spatial) %\u0026gt;%\rselect(GEOID10, NAMELSAD10) %\u0026gt;%\rcbind(police_spatial@data) %\u0026gt;%\rselect(OBJECTID, GEOID10, NAMELSAD10)\r\rJoin Data\rNow to create a nice clean simple featur object, I join by the GEOID. It is really helpful for you to learn more about these identifiers and how they are constructed if you want to play more with Census data.\nYou can learn more about them here - Understanding Geographic Identifiers (GEOIDs). You will see there how the identifiers are constructed from large to small components. If you are wondering whey this might be important for you, I have lost cost of how many times I have had to piece my own identifiers together from scattered data elements.\npolice_incidents_final \u0026lt;- police_spatial %\u0026gt;%\rst_as_sf() %\u0026gt;%\rleft_join(overlay)\r\rTest Plot\rNow I am going to do a quick base R test plot to make sure that everything matched the way I intended.\nplot(police_incidents_final[\u0026quot;GEOID10\u0026quot;])\r\r\rWhat Can You Do With This?\rBasic Relationship Plot\rI now have some census data combined with my police incident records. Here, I am grouping my data by census tract and then creating a count of incidents by tract. After that, I throw together a quick exploratory plot of the relationship between Vacant Housing and count of police incidents. This is in no way explanatory - just exploratory. Please always do your due diligence before jumping to assumptions in exploratory analysis.\npolice_incidents_final %\u0026gt;%\ras_tibble() %\u0026gt;%\rgroup_by(GEOID10) %\u0026gt;%\rsummarise(inc_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rselect(GEOID10, inc_count) %\u0026gt;%\rright_join(wake_tracts) %\u0026gt;%\rfilter(inc_count \u0026gt; 100) %\u0026gt;%\rggplot(aes(VACANT, inc_count)) +\rgeom_point() +\rgeom_smooth() +\rtheme_minimal() +\rlabs(x = \u0026quot;Vacant Housing\u0026quot;, y = \u0026quot;Police Incident Count\u0026quot;, title = \u0026quot;Relationship Between Police Incidents and Vacant Housing\u0026quot;)\r\rIncident Count by Census Tract\rNow for the good stuff (or at least I think so)! I want to create a choropleth map of Wake County that is colored based on the count of police incidents in each Census Tract.\npolice_incidents_final %\u0026gt;%\ras_tibble() %\u0026gt;%\rgroup_by(GEOID10) %\u0026gt;%\rsummarise(inc_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rselect(GEOID10, inc_count) %\u0026gt;%\rright_join(wake_tracts) %\u0026gt;%\rggplot() +\rgeom_sf(aes(fill = inc_count)) +\rscale_fill_viridis_c(\u0026quot;Incident Count\u0026quot;) +\rjason_theme\r\rAssault Count by Census Tract\rNow, I am going to go one level deeper and create a choropleth map of Wake County that is colored based on the count of police incidents categorized as ASSAULT.\npolice_incidents_final %\u0026gt;%\ras_tibble() %\u0026gt;%\rfilter(crime_category == \u0026quot;ASSAULT\u0026quot;) %\u0026gt;%\rgroup_by(GEOID10) %\u0026gt;%\rsummarise(assault_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rselect(GEOID10, assault_count) %\u0026gt;%\rright_join(wake_tracts) %\u0026gt;%\rggplot() +\rgeom_sf(aes(fill = assault_count)) +\rscale_fill_viridis_c(\u0026quot;Assault Count\u0026quot;) +\rjason_theme\r\rSpatial Comparison\rWhat if I want to pul out two features and plot them side by side? Look no further than the cowplot package!\nmap_1 \u0026lt;- police_incidents_final %\u0026gt;%\ras_tibble() %\u0026gt;%\rfilter(crime_category == \u0026quot;ASSAULT\u0026quot;) %\u0026gt;%\rgroup_by(GEOID10) %\u0026gt;%\rsummarise(assault_count = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rselect(GEOID10, assault_count) %\u0026gt;%\rright_join(wake_tracts) %\u0026gt;%\rggplot() +\rgeom_sf(aes(fill = assault_count)) +\rscale_fill_viridis_c(\u0026quot;Assault Count\u0026quot;) +\rjason_theme\rmap_2 \u0026lt;- wake_tracts %\u0026gt;%\rggplot() +\rgeom_sf(aes(fill = VACANT)) +\rscale_fill_viridis_c(\u0026quot;Vacant Housing\u0026quot;) +\rjason_theme\rcowplot::plot_grid(map_1, map_2, labels = \u0026quot;AUTO\u0026quot;, nrow = 1, ncol = 2)\r\r\rGoogle Trends\rI wanted to also take a second to explore something that may be more relevant for you. I am not going to walk through this in detail but want to provide it as an example of another pretty cool way you can combine and use spatial data in R.\nI am going to play around with some Google Trends data published by their News Lab. This is a pretty cool thing they do that is apparently targeted at training journalists to use Google data more effectively.\n\rDownload Data \u0026amp; Separate\rgoogle_dat \u0026lt;- read_csv(\u0026quot;https://raw.githubusercontent.com/googletrends/data/master/Search_Data_US_Congressional_District_04Nov2018.csv\u0026quot;)\rgoogle_dat_rankings \u0026lt;- google_dat %\u0026gt;%\rselect(1:13) %\u0026gt;%\rgather(\u0026quot;ranking\u0026quot;, \u0026quot;issue\u0026quot;, 4:13) %\u0026gt;%\rfilter(State == \u0026quot;NC\u0026quot;) %\u0026gt;%\rmutate(CD115FP = str_remove_all(Code, \u0026quot;[A-Za-z-]+\u0026quot;)) %\u0026gt;%\rmutate(ranking = str_to_title(ranking))\rgoogle_dat_issues \u0026lt;- google_dat %\u0026gt;%\rselect(1:3, 14:142) %\u0026gt;%\rgather(\u0026quot;other_issue\u0026quot;, \u0026quot;search_freq\u0026quot;, 4:132) %\u0026gt;%\rfilter(State == \u0026quot;NC\u0026quot;) %\u0026gt;%\rmutate(CD115FP = str_remove_all(Code, \u0026quot;[A-Za-z-]+\u0026quot;))\r\rTop Ranked Issues For NC\rgoogle_dat_rankings %\u0026gt;%\rgroup_by(ranking, issue) %\u0026gt;%\rsummarise(total = n()) %\u0026gt;%\rungroup() %\u0026gt;%\rfilter(ranking == \u0026quot;First\u0026quot;) %\u0026gt;%\rkableExtra::kable() %\u0026gt;%\rkableExtra::kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;), full_width = F, position = \u0026quot;left\u0026quot;)\r\r\rranking\r\rissue\r\rtotal\r\r\r\r\r\rFirst\r\rCommon core\r\r1\r\r\r\rFirst\r\rHealth care\r\r12\r\r\r\r\r\rCongressional Districts Polygons\rdistricts \u0026lt;- tigris::congressional_districts()\rdistricts_sf \u0026lt;- districts %\u0026gt;%\rst_as_sf() %\u0026gt;%\rfilter(STATEFP == \u0026quot;37\u0026quot;)\rplot(districts_sf[\u0026quot;CD115FP\u0026quot;])\r\rLabels \u0026amp; Health Care Map\rI will at least explain here that the first thing I am doing is creating a tibble of the centroids of the congressional district polygons. I am doing this so I can throw some labels on my map as points of reference.\ncentroids_df \u0026lt;- districts %\u0026gt;%\rst_as_sf() %\u0026gt;%\rfilter(STATEFP == \u0026quot;37\u0026quot;) %\u0026gt;%\ras_Spatial() %\u0026gt;%\rcoordinates() %\u0026gt;%\ras_tibble() %\u0026gt;%\rrename(\u0026quot;Long\u0026quot; = V1, \u0026quot;Lat\u0026quot; = V2) %\u0026gt;%\rmutate(CD115FP = filter(districts@data, STATEFP == \u0026quot;37\u0026quot;)$CD115FP)\rgoogle_dat_issues %\u0026gt;%\rfilter(other_issue == \u0026quot;Health care\u0026quot;) %\u0026gt;%\rselect(CD115FP, search_freq) %\u0026gt;%\rright_join(districts_sf) %\u0026gt;%\rggplot() +\rgeom_sf(aes(fill = search_freq)) +\rscale_fill_viridis_c(\u0026quot;Search Frequency\u0026quot;, direction = -1) +\rgeom_label(data = centroids_df, aes(Long, Lat, label = CD115FP)) +\rlabs(title = \u0026quot;Google Search Frequency - Health Care\u0026quot;) +\rjason_theme\r\r\r","date":1553029740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553029740,"objectID":"0c67e3bedf9160f225fd2149a62d5f3e","permalink":"/post/2019-03-18-elon-geospatial/","publishdate":"2019-03-19T21:09:00Z","relpermalink":"/post/2019-03-18-elon-geospatial/","section":"post","summary":"Welcome to the wonderful world of R-Spatial! I really enjoy playing around with spatial data in R and for some reason find it much easier than ArcGIS (#sorrynotsorry Esri). Please keep in mind, as with everything I do in R, I am self taught and rely heavily on publicly available resources. My way of doing things may not always be the best or perfect, it is just how I was able to make sense of it.","tags":null,"title":"I Like It When You Call Me Large SpatialPolygonsDataFrame","type":"post"},{"authors":null,"categories":null,"content":"\rThis post was inspired by the MUSA Masterclass provided very graciously by Ken Steif and James Cheshire. If you aren’t familiar with the program I would strongly encourage you to check it out - UPenn MUSA Program.\nI decided to use open data from the City of Raleigh for my exploration. All data can be found on The City of Raleigh’s open data portal. The primary data I am using is contained in the Raleigh Police Incidents (NIBRS) dataset. Each row represents a report made by a police officer.\nLoad Required Packages\rTrying to keep it as simple as possible while leveraging some tidyverse tricks I’ve been trying to learn. Forcing myself to use them seems to be a good idea.\nlibrary(sf)\rlibrary(tidyverse)\rlibrary(RANN2)\r\rRetrieve Data\rWould strongly recommend downloading this data and reading from your computer. Here I am reading the data directly from the GeoJSON API endpoints.\nraleigh_police \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/24c0b37fa9bb4e16ba8bcaa7e806c615_0.geojson\u0026quot;)\rwake_police_dpts \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/23094dc3a7b84682898c0a2c27290066_0.geojson\u0026quot;)\rraleigh_limits \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/4303065aa95441308cc7224cf6246782_0.geojson\u0026quot;) %\u0026gt;%\rfilter(LONG_NAME == \u0026quot;RALEIGH\u0026quot;)\r\rFilter Missing Data\rTo prevent some problems down the road, I am filtering out all incidents that are missing spatial attributes.\nraleigh_police \u0026lt;- raleigh_police %\u0026gt;%\rfilter(is.na(latitude) != TRUE)\r\rTest Plots\rJust throwing out some quick test plots to make sure everything is working as anticipated.\nplot(raleigh_police$geometry, col = \u0026quot;grey\u0026quot;)\rplot(wake_police_dpts$geometry, col = \u0026quot;grey\u0026quot;)\r\rCheck for matching projection\rChecking for matching projections for plotting and k nearest neighbor clustering.\nst_crs(raleigh_police)\r## Coordinate Reference System:\r## EPSG: 4326 ## proj4string: \u0026quot;+proj=longlat +datum=WGS84 +no_defs\u0026quot;\rst_crs(wake_police_dpts)\r## Coordinate Reference System:\r## EPSG: 4326 ## proj4string: \u0026quot;+proj=longlat +datum=WGS84 +no_defs\u0026quot;\r\rCreate Nested Tibble\rHere I am nesting the data by crime description so I can apply the clustering function. This creates a column of tibbles for each crime description which will become important as we try to distinguish densities in later steps.\nraleigh_police_nested \u0026lt;- raleigh_police %\u0026gt;%\rgroup_by(crime_description) %\u0026gt;%\rnest()\r\rCreate Clustering Function\rNext, I wrote a function to apply to my column of tibbles. I am using the nn2 function from the RANN2 package to perform k nearest neighbor clustering. This function clusters points by law enforcement stations.\nf \u0026lt;- function(dat) {\rnn2(st_coordinates(wake_police_dpts), st_coordinates(dat), k =1) %\u0026gt;%\rdata.frame() %\u0026gt;%\ras_tibble() %\u0026gt;%\rgroup_by(nn.idx) %\u0026gt;%\rsummarise(cnt = n()) %\u0026gt;%\rright_join(wake_police_dpts, by = c(\u0026quot;nn.idx\u0026quot; = \u0026quot;OBJECTID\u0026quot;)) %\u0026gt;%\rselect(-nn.idx) %\u0026gt;%\rfilter(is.na(cnt) != TRUE)\r}\r\rMap Clustering Function to Tibble\rNext, I leverage the purrr package to map the function to the column of tibbles to create a new column of tibbles containing counts by law enforcement stations.\nraleigh_police_nested \u0026lt;- raleigh_police_nested %\u0026gt;%\rmutate(closest = purrr::map(.x = data, .f = ~f(.x)))\r\rDefine Crime Description\rNow we are ready to explore the results. The thought here is potentially a shiny application where you could specify a crime description and produce a series of informative plots. I start by defining a new object, crime_des, to filter for only Traffic/DWI Incidents.\ncrime_des \u0026lt;- \u0026quot;Traffic/DWI (Driving While Impaired)\u0026quot;\r\rExtract Nested Tibble\rHere, I am creating two new objects for plotting based on the crime description I just specified.\ndat \u0026lt;- raleigh_police_nested %\u0026gt;%\rfilter(crime_description == crime_des) %\u0026gt;%\r.$closest %\u0026gt;%\r.[[1]] %\u0026gt;%\rst_as_sf()\r# Also creating secondary object for density plots\rdat2 \u0026lt;- raleigh_police %\u0026gt;%\rfilter(crime_description == crime_des) %\u0026gt;%\rst_coordinates() %\u0026gt;%\ras_tibble()\r\rDensity Plot\rNow for the fun! First is a density map of Traffic/DWI incidents.\ndat2 %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rstat_density_2d(aes(X, Y, fill = ..level..), geom = \u0026quot;polygon\u0026quot;, alpha = 0.6) +\rviridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\r\rHexbin Plot\rNext is a Hexbin map of Traffic/DWI Incidents.\ndat2 %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rgeom_hex(aes(X,Y), alpha = 0.6) +\rviridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\r\rClustering By Police Stations\rFinally, is a map of law enforcement stations where the count of clustered incidents is mapped to the size of the point.\ndat %\u0026gt;%\rst_coordinates() %\u0026gt;%\ras_tibble() %\u0026gt;%\rmutate(cnt = dat$cnt, AGENCY = dat$AGENCY) %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rgeom_point(aes(X, Y, size = cnt, color = AGENCY), alpha = 0.8) +\rscale_color_brewer(palette = \u0026quot;Spectral\u0026quot;, direction = -1, name = \u0026quot;Agency\u0026quot;) +\rscale_size(name = \u0026quot;Count of Incidents\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Clustering of %s Incidents by LE Stations\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\rMaybe one more time just for fun!\n\rDefine Crime Description Again\rcrime_des \u0026lt;- \u0026quot;Assault/Simple\u0026quot;\r\rExtract Nested Tibble Again\rdat \u0026lt;- raleigh_police_nested %\u0026gt;%\rfilter(crime_description == crime_des) %\u0026gt;%\r.$closest %\u0026gt;%\r.[[1]] %\u0026gt;%\rst_as_sf()\r# Also creating secondary object for density plots\rdat2 \u0026lt;- raleigh_police %\u0026gt;%\rfilter(crime_description == crime_des) %\u0026gt;%\rst_coordinates() %\u0026gt;%\ras_tibble()\r\rDensity Plot Again\rdat2 %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rstat_density_2d(aes(X, Y, fill = ..level..), geom = \u0026quot;polygon\u0026quot;, alpha = 0.6) +\rviridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\r\rHexbin Plot Again\rdat2 %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rgeom_hex(aes(X,Y), alpha = 0.6) +\rviridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\r\rClustering By Police Stations Again\rdat %\u0026gt;%\rst_coordinates() %\u0026gt;%\ras_tibble() %\u0026gt;%\rmutate(cnt = dat$cnt, AGENCY = dat$AGENCY) %\u0026gt;%\rggplot() +\rgeom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) +\rgeom_point(aes(X, Y, size = cnt, color = AGENCY), alpha = 0.8) +\rscale_color_brewer(palette = \u0026quot;Spectral\u0026quot;, direction = -1, name = \u0026quot;Agency\u0026quot;) +\rscale_size(name = \u0026quot;Count of Incidents\u0026quot;) +\rlabs(title = sprintf(\u0026quot;Clustering of %s Incidents by LE Stations\u0026quot;, crime_des),\rcaption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) +\rtheme(text = element_text(family = \u0026quot;Roboto\u0026quot;),\rplot.title = element_text(size = 14),\rpanel.background = element_blank(),\raxis.text = element_blank(),\raxis.title = element_blank(),\raxis.ticks = element_blank(),\raxis.line = element_blank())\rI really appreciate the class taught by James Cheshire even though this is a little bit of a deviation from clustering to roads. I am thinking something like this could be suited for a shiny application. Not sure if I will ever get around to making that happen.\n\r","date":1542575340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542575340,"objectID":"48b98ee42631e7c4028220e9fafdc4bb","permalink":"/post/2018-11-17-raleigh-police/","publishdate":"2018-11-18T21:09:00Z","relpermalink":"/post/2018-11-17-raleigh-police/","section":"post","summary":"This post was inspired by the MUSA Masterclass provided very graciously by Ken Steif and James Cheshire. If you aren’t familiar with the program I would strongly encourage you to check it out - UPenn MUSA Program.\nI decided to use open data from the City of Raleigh for my exploration. All data can be found on The City of Raleigh’s open data portal. The primary data I am using is contained in the Raleigh Police Incidents (NIBRS) dataset.","tags":null,"title":"Spatial Exploration - MUSA Masterclass","type":"post"},{"authors":null,"categories":null,"content":"\rlibrary(tidyverse)\rlibrary(lubridate)\rbulk_dat \u0026lt;- read_csv(\u0026quot;https://www.dallasopendata.com/api/views/ftja-9jxd/rows.csv\u0026quot;,\rcol_types = cols(offensereportingofficerbadge2 = col_character(),\roffensebeat = col_character())) %\u0026gt;%\rmutate(offensedate = as.Date(offensedate, format = \u0026quot;%m/%d/%Y\u0026quot;))\rbulk_dat \u0026lt;- bulk_dat %\u0026gt;%\rmutate(hour = hour(offensetimeofoccurence2)) %\u0026gt;%\rmutate(age = as.integer(offenseage)) %\u0026gt;%\rmutate(month = month(offensedate))\rbulk_dat %\u0026gt;%\rggplot(aes(age)) +\rgeom_histogram(aes(y = ..density..),\rbinwidth = 5, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) +\rgeom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) +\rgeom_vline(aes(xintercept = mean(age, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1)\rbulk_dat %\u0026gt;%\rggplot(aes(hour)) +\rgeom_histogram(aes(y = ..density..),\rbinwidth = 2, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) +\rgeom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) +\rgeom_vline(aes(xintercept = mean(hour, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1)\rbulk_dat %\u0026gt;%\rggplot(aes(month)) +\rgeom_histogram(aes(y = ..density..),\rbinwidth = 1, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) +\rgeom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) +\rgeom_vline(aes(xintercept = mean(month, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1)\r","date":1542056940,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542056940,"objectID":"744d2d802d93c9fad3b9182be42a0c37","permalink":"/post/2018-11-12-crime-age-stats/","publishdate":"2018-11-12T21:09:00Z","relpermalink":"/post/2018-11-12-crime-age-stats/","section":"post","summary":"library(tidyverse)\rlibrary(lubridate)\rbulk_dat \u0026lt;- read_csv(\u0026quot;https://www.dallasopendata.com/api/views/ftja-9jxd/rows.csv\u0026quot;,\rcol_types = cols(offensereportingofficerbadge2 = col_character(),\roffensebeat = col_character())) %\u0026gt;%\rmutate(offensedate = as.Date(offensedate, format = \u0026quot;%m/%d/%Y\u0026quot;))\rbulk_dat \u0026lt;- bulk_dat %\u0026gt;%\rmutate(hour = hour(offensetimeofoccurence2)) %\u0026gt;%\rmutate(age = as.integer(offenseage)) %\u0026gt;%\rmutate(month = month(offensedate))\rbulk_dat %\u0026gt;%\rggplot(aes(age)) +\rgeom_histogram(aes(y = ..density..),\rbinwidth = 5, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) +\rgeom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) +\rgeom_vline(aes(xintercept = mean(age, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1)\rbulk_dat %\u0026gt;%\rggplot(aes(hour)) +\rgeom_histogram(aes(y = .","tags":null,"title":"Age Is Just A Number…Statistically Speaking","type":"post"},{"authors":null,"categories":["R"],"content":"  Synopsis In this analysis I amd concerned with two primary points. Which event types have the greatest health impact and the greatest economic impact. I begin my work with data processing to create usable objects for results visualization. I finish my analysis with two plots and a final table.\n Package Load Load packages required for analysis.\nrequire(tidyverse) require(lubridate) require(kableExtra)  Data Import Leveraging read_csv from the readr packackge included with tidyverse to import the dataset.\nweather_dat = read_csv(\u0026quot;data/repdata%2Fdata%2FStormData.csv.bz2\u0026quot;)  Data Processing The first thing I want to do is convert BGN_DATE to a usable longitudinal variable. I am doing this so I can provide change-over-time information as I attempt to answer both questions presented. I am storing the result as a new object so I don’t mess with my original data import object.\nnew_dat = weather_dat %\u0026gt;% mutate(BGN_DATE = str_trim(str_extract(BGN_DATE, \u0026quot;^\\\\S+\\\\s+\u0026quot;))) %\u0026gt;% mutate(BGN_DATE = as.POSIXct(BGN_DATE, format = \u0026quot;%m/%d/%Y\u0026quot;)) I also want to select the most recent ten years of data. Even though there are data points from 1950-01-03 to 2011-11-30, there are a lot of gaps in data collection the farther back you go.\nnew_dat = new_dat %\u0026gt;% filter(year(BGN_DATE) \u0026gt;= (year(max(BGN_DATE)) - 10)) Question 1 Processing I want to attempt to provide my version of an answer to question 1 in three steps. This section will deal with data processing and later I will work through visual creation. The first thing I am doing is creating a fatalities object representative of the top 10 fatality causing event types.\nquest_1_fat = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(fatalities_count = sum(FATALITIES)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, fatalities_count) The next step is to create an injuries object representative of the top 10 injury causing event types. You will notice this step is just a simple modification of the first.\nquest_1_inj = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(injury_count = sum(INJURIES)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, injury_count) The third and final step starts by filtering for event types that are common between quest_1_fat and quest_1_inj, then consolidates data points by month, sums up injuries and fatalities by event type, and then finally gathers injuries and fatalities into one variable.\nquest_1_final = new_dat %\u0026gt;% filter(EVTYPE %in% quest_1_fat$EVTYPE \u0026amp; EVTYPE %in% quest_1_inj$EVTYPE) %\u0026gt;% mutate(BGN_DATE = floor_date(BGN_DATE, unit = \u0026quot;1 month\u0026quot;)) %\u0026gt;% group_by(BGN_DATE, EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;INJURIES\u0026quot;, \u0026quot;FATALITIES\u0026quot;), sum) %\u0026gt;% ungroup() %\u0026gt;% gather(\u0026quot;measure\u0026quot;, \u0026quot;count\u0026quot;, 3:4)  Question 2 Processing To begin question two, I am writing a function to help me convert the character values for thousand, million, and billion to their numeric value as a multiplier for the PROPDMG and CROPDMG variables.\nf = function(dat) { if(dat == \u0026quot;K\u0026quot;) { 1000 } else if (dat == \u0026quot;M\u0026quot;) { 1000000 } else if (dat == \u0026quot;B\u0026quot;) { 1000000000 } else { NA } } Next, I filter out NA values for property and crop damage, create two new variables that replace the character values with integer multipliers, and then calculate actual property and crop damage values.\nnew_dat = new_dat %\u0026gt;% filter(is.na(PROPDMGEXP) == FALSE) %\u0026gt;% filter(is.na(CROPDMGEXP) == FALSE) %\u0026gt;% mutate(prop_mult = as.integer(map_chr(.x = PROPDMGEXP, .f = f))) %\u0026gt;% mutate(crop_mult = as.integer(map_chr(.x = CROPDMGEXP, .f = f))) %\u0026gt;% mutate(prop_dmg = PROPDMG * prop_mult) %\u0026gt;% mutate(crop_dmg = CROPDMG * crop_mult) Very similar to question one, I am now going to look at the top ten event types by total property damage over the last ten years.\nquest_2_prop = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(total_dmg = sum(prop_dmg)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, total_dmg) Here again, I am creating an object that has the top ten event types by total crop damage over the last ten years.\nquest_2_crop = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(total_dmg = sum(crop_dmg)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, total_dmg) As a final step, I am creating an object that filters for only event types that occur in both top ten lists and then calculates total property and crop damage over time.\nquest_2_final = new_dat %\u0026gt;% filter(EVTYPE %in% quest_2_prop$EVTYPE \u0026amp; EVTYPE %in% quest_2_crop$EVTYPE) %\u0026gt;% mutate(BGN_DATE = floor_date(BGN_DATE, unit = \u0026quot;1 month\u0026quot;)) %\u0026gt;% group_by(BGN_DATE, EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;prop_dmg\u0026quot;, \u0026quot;crop_dmg\u0026quot;), sum) %\u0026gt;% ungroup() %\u0026gt;% gather(\u0026quot;measure\u0026quot;, \u0026quot;total_dmg\u0026quot;, 3:4)   Results Question 1 Results The goal of this plot is to show the most impactful event types over the past ten years. For this, I am using a faceted ggplot column visualization.\nquest_1_final %\u0026gt;% ggplot(aes(as.character(year(BGN_DATE)), count, fill = measure)) + geom_col() + facet_wrap(~EVTYPE, scales = \u0026quot;free_y\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), legend.position = \u0026quot;bottom\u0026quot;, axis.text.x = element_text(angle = 90, vjust = 0.5), axis.title = element_blank(), panel.background = element_blank(), strip.background = element_rect(fill = \u0026quot;#146a90\u0026quot;), strip.text = element_text(color = \u0026quot;white\u0026quot;, face = \u0026quot;bold\u0026quot;)) + scale_fill_viridis_d(\u0026quot;\u0026quot;, direction = -1)  Question 2 Results As with question one, the goal of this plot is to show the most impactful event types over the past ten years in terms of property and crop damage. For this, I am using a faceted ggplot column visualization that is modeled after the question one plot for consistency.\nquest_2_final %\u0026gt;% ggplot(aes(as.character(year(BGN_DATE)), total_dmg/1000000, fill = measure)) + geom_col() + facet_wrap(~EVTYPE, scales = \u0026quot;free_y\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), legend.position = \u0026quot;bottom\u0026quot;, axis.text.x = element_text(angle = 90, vjust = 0.5), axis.title.x = element_blank(), panel.background = element_blank(), strip.background = element_rect(fill = \u0026quot;#146a90\u0026quot;), strip.text = element_text(color = \u0026quot;white\u0026quot;, face = \u0026quot;bold\u0026quot;)) + labs(y = \u0026quot;Total Damage (millions)\u0026quot;) + scale_fill_viridis_d(\u0026quot;\u0026quot;, direction = -1, labels = c(\u0026quot;Crop Damage\u0026quot;, \u0026quot;Property Damage\u0026quot;)) + scale_y_continuous(labels = scales::dollar_format())  Overall What about the worst in terms of economic impact and health? If you look at both question one and two results you will find only one event type consistent between both.\nnew_dat %\u0026gt;% filter(EVTYPE %in% quest_1_fat$EVTYPE \u0026amp; EVTYPE %in% quest_1_inj$EVTYPE \u0026amp; EVTYPE %in% quest_2_prop$EVTYPE \u0026amp; EVTYPE %in% quest_2_crop$EVTYPE) %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;INJURIES\u0026quot;, \u0026quot;FATALITIES\u0026quot;, \u0026quot;CROPDMG\u0026quot;, \u0026quot;PROPDMG\u0026quot;), sum) %\u0026gt;% kable(format = \u0026quot;html\u0026quot;, align = \u0026quot;lcccc\u0026quot;, col.names = c(\u0026quot;Event Type\u0026quot;, \u0026quot;Injuries\u0026quot;, \u0026quot;Fatalities\u0026quot;, \u0026quot;Crop Damage\u0026quot;, \u0026quot;Property Damage\u0026quot;), format.args = list(big.mark = \u0026quot;,\u0026quot;)) %\u0026gt;% kable_styling(full_width = TRUE)   Event Type  Injuries  Fatalities  Crop Damage  Property Damage      THUNDERSTORM WIND  1,400  130  66,663  862,257.4       ","date":1535922540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535922540,"objectID":"a4a975c6775cf24d6698befa8c0728ae","permalink":"/post/2018-09-02-reproducible-research/","publishdate":"2018-09-02T21:09:00Z","relpermalink":"/post/2018-09-02-reproducible-research/","section":"post","summary":"Synopsis In this analysis I amd concerned with two primary points. Which event types have the greatest health impact and the greatest economic impact. I begin my work with data processing to create usable objects for results visualization. I finish my analysis with two plots and a final table.\n Package Load Load packages required for analysis.\nrequire(tidyverse) require(lubridate) require(kableExtra)  Data Import Leveraging read_csv from the readr packackge included with tidyverse to import the dataset.","tags":["R Markdown","analysis","reproducible"],"title":"Health and Economic Impact of Storms and Severe Weather Events","type":"post"},{"authors":["Jason Jones"],"categories":null,"content":"","date":1527825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527825600,"objectID":"f3e51c17dad960210e18ca471df74b94","permalink":"/talk/open-data/","publishdate":"2018-06-01T00:00:00-04:00","relpermalink":"/talk/open-data/","section":"talk","summary":"Talk on the past, present, and future of local government open data given at the 2018 Innovations in Planning for Better Community Housing and Health Symposium at UNCG.","tags":["open data","data"],"title":"Government Open Data","type":"talk"},{"authors":null,"categories":["R"],"content":"  Package Import Load necessary packages and set one global option.\nlibrary(tidyverse) library(pdftools) library(tidytext) library(knitr) library(kableExtra) options(stringsAsFactors = FALSE)  Retrieve File Download the file from the City of Raleigh website, read that file in as a character vector, and delete the downloaded file from the directory.\ndownload.file(\u0026quot;https://www.raleighnc.gov/content/BudgetManagement/Documents/Budget/Archive/2018/FY2018AdoptedBudget20160612.pdf\u0026quot;, \u0026quot;FY2018AdoptedBudget.pdf\u0026quot;, mode = \u0026quot;wb\u0026quot;) txt = pdf_text(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;) unlink(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;)  Create Data Frame Create a page number character vector, create a data frame by binding the page number character vector with the extracted text, and finally “unnest” all of the page text into individual words.\npage = as.character(1:length(txt)) df = data.frame(cbind(page, txt)) budget_words = df %\u0026gt;% unnest_tokens(word, txt)  Cleaning Remove stop words and save as clean object, join sentiment lexicon with clean object, and group the object by page and sentiments before summarising.\ncleaned = budget_words %\u0026gt;% anti_join(stop_words) sentiment = cleaned %\u0026gt;% inner_join(get_sentiments(\u0026quot;nrc\u0026quot;)) sent_count = sentiment %\u0026gt;% group_by(page, sentiment) %\u0026gt;% summarise(sent_count = n()) %\u0026gt;% ungroup() %\u0026gt;% mutate(page = as.integer(page))  Visualize  Negative Word Table   Word  Word Count      APPROPRIATION  77    BONDS  50    DEBT  219    EMERGENCY  67    EXPENDITURE  123    FEE  136    INCOME  65    RISK  31    TAX  153    WASTE  122      Trust Word Table   Word  Word Count      BUDGET  400    CENTER  196    COUNCIL  173    GRANT  85    IMPROVEMENT  93    MANAGEMENT  165    ORDINANCE  88    PLANNING  77    RESOURCES  105    SYSTEM  101      ","date":1525036140,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525036140,"objectID":"5c491dc7eff91501e4bdcf15639daac9","permalink":"/post/2018-04-29-raleigh-sentiment/","publishdate":"2018-04-29T21:09:00Z","relpermalink":"/post/2018-04-29-raleigh-sentiment/","section":"post","summary":"Package Import Load necessary packages and set one global option.\nlibrary(tidyverse) library(pdftools) library(tidytext) library(knitr) library(kableExtra) options(stringsAsFactors = FALSE)  Retrieve File Download the file from the City of Raleigh website, read that file in as a character vector, and delete the downloaded file from the directory.\ndownload.file(\u0026quot;https://www.raleighnc.gov/content/BudgetManagement/Documents/Budget/Archive/2018/FY2018AdoptedBudget20160612.pdf\u0026quot;, \u0026quot;FY2018AdoptedBudget.pdf\u0026quot;, mode = \u0026quot;wb\u0026quot;) txt = pdf_text(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;) unlink(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;)  Create Data Frame Create a page number character vector, create a data frame by binding the page number character vector with the extracted text, and finally “unnest” all of the page text into individual words.","tags":["R Markdown","budget","sentiment"],"title":"City of Raleigh Budget Sentiment Analysis","type":"post"},{"authors":["Jason Jones"],"categories":null,"content":"","date":1515474000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515474000,"objectID":"c91f9fa5241d0f4fa5c8c444fc0484f9","permalink":"/publication/i-have-to-ask-you/","publishdate":"2018-01-09T00:00:00-05:00","relpermalink":"/publication/i-have-to-ask-you/","section":"publication","summary":"Apparently ELGL co-founder Kent Wyatt moonlights as a private background investigator, diving deep into the past lives of all of his ELGL family. Sometimes I forget that I spent five years as a track and field athlete while also receiving a quality education at North Carolina State University. I mean, it isn’t really something that you whip out of your “fun facts bag” all that frequently. Discussing the intricate physics of spinning in a circle with a sixteen pound cast iron ball before releasing it in a blur of chalk dust and grunting doesn’t make for the best dinner conversation.","tags":["ELGL"],"title":"I Have to Ask You","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]