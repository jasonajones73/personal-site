[
  {
    "authors": null,
    "categories": null,
    "content": " This post was inspired by the MUSA Masterclass provided very graciously by Ken Steif and James Cheshire. If you aren’t familiar with the program I would strongly encourage you to check it out - UPenn MUSA Program.\nI decided to use open data from the City of Raleigh for my exploration. All data can be found on The City of Raleigh’s open data portal. The primary data I am using is contained in the Raleigh Police Incidents (NIBRS) dataset. Each row represents a report made by a police officer.\nLoad Required Packages Trying to keep it as simple as possible while leveraging some tidyverse tricks I’ve been trying to learn. Forcing myself to use them seems to be a good idea.\nlibrary(sf) library(tidyverse) library(RANN2)  Retrieve Data Would strongly recommend downloading this data and reading from your computer. Here I am reading the data directly from the GeoJSON API endpoints.\nraleigh_police \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/24c0b37fa9bb4e16ba8bcaa7e806c615_0.geojson\u0026quot;, \u0026quot;OGRGeoJSON\u0026quot;) wake_police_dpts \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/23094dc3a7b84682898c0a2c27290066_0.geojson\u0026quot;, \u0026quot;OGRGeoJSON\u0026quot;) raleigh_limits \u0026lt;- read_sf(\u0026quot;https://opendata.arcgis.com/datasets/4303065aa95441308cc7224cf6246782_0.geojson\u0026quot;, \u0026quot;OGRGeoJSON\u0026quot;) %\u0026gt;% filter(LONG_NAME == \u0026quot;RALEIGH\u0026quot;)  Filter Missing Data To prevent some problems down the road, I am filtering out all incidents that are missing spatial attributes.\nraleigh_police \u0026lt;- raleigh_police %\u0026gt;% filter(is.na(latitude) != TRUE)  Test Plots Just throwing out some quick test plots to make sure everything is working as anticipated.\nplot(raleigh_police$geometry, col = \u0026quot;grey\u0026quot;) plot(wake_police_dpts$geometry, col = \u0026quot;grey\u0026quot;)  Check for matching projection Checking for matching projections for plotting and k nearest neighbor clustering.\nst_crs(raleigh_police) ## Coordinate Reference System: ## EPSG: 4326 ## proj4string: \u0026quot;+proj=longlat +datum=WGS84 +no_defs\u0026quot; st_crs(wake_police_dpts) ## Coordinate Reference System: ## EPSG: 4326 ## proj4string: \u0026quot;+proj=longlat +datum=WGS84 +no_defs\u0026quot;  Create Nested Tibble Here I am nesting the data by crime description so I can apply the clustering function. This creates a column of tibbles for each crime description which will become important as we try to distinguish densities in later steps.\nraleigh_police_nested \u0026lt;- raleigh_police %\u0026gt;% group_by(crime_description) %\u0026gt;% nest()  Create Clustering Function Next, I wrote a function to apply to my column of tibbles. I am using the nn2 function from the RANN2 package to perform k nearest neighbor clustering. This function clusters points by law enforcement stations.\nf \u0026lt;- function(dat) { nn2(st_coordinates(wake_police_dpts), st_coordinates(dat), k =1) %\u0026gt;% data.frame() %\u0026gt;% as_tibble() %\u0026gt;% group_by(nn.idx) %\u0026gt;% summarise(cnt = n()) %\u0026gt;% right_join(wake_police_dpts, by = c(\u0026quot;nn.idx\u0026quot; = \u0026quot;OBJECTID\u0026quot;)) %\u0026gt;% select(-nn.idx) %\u0026gt;% filter(is.na(cnt) != TRUE) }  Map Clustering Function to Tibble Next, I leverage the purrr package to map the function to the column of tibbles to create a new column of tibbles containing counts by law enforcement stations.\nraleigh_police_nested \u0026lt;- raleigh_police_nested %\u0026gt;% mutate(closest = purrr::map(.x = data, .f = ~f(.x)))  Define Crime Description Now we are ready to explore the results. The thought here is potentially a shiny application where you could specify a crime description and produce a series of informative plots. I start by defining a new object, crime_des, to filter for only Traffic/DWI Incidents.\ncrime_des \u0026lt;- \u0026quot;Traffic/DWI (Driving While Impaired)\u0026quot;  Extract Nested Tibble Here, I am creating two new objects for plotting based on the crime description I just specified.\ndat \u0026lt;- raleigh_police_nested %\u0026gt;% filter(crime_description == crime_des) %\u0026gt;% .$closest %\u0026gt;% .[[1]] %\u0026gt;% st_as_sf() # Also creating secondary object for density plots dat2 \u0026lt;- raleigh_police %\u0026gt;% filter(crime_description == crime_des) %\u0026gt;% st_coordinates() %\u0026gt;% as_tibble()  Density Plot Now for the fun! First is a density map of Traffic/DWI incidents.\ndat2 %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + stat_density_2d(aes(X, Y, fill = ..level..), geom = \u0026quot;polygon\u0026quot;, alpha = 0.6) + viridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) + labs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank())  Hexbin Plot Next is a Hexbin map of Traffic/DWI Incidents.\ndat2 %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + geom_hex(aes(X,Y), alpha = 0.6) + viridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) + labs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank())  Clustering By Police Stations Finally, is a map of law enforcement stations where the count of clustered incidents is mapped to the size of the point.\ndat %\u0026gt;% st_coordinates() %\u0026gt;% as_tibble() %\u0026gt;% mutate(cnt = dat$cnt, AGENCY = dat$AGENCY) %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + geom_point(aes(X, Y, size = cnt, color = AGENCY), alpha = 0.8) + scale_color_brewer(palette = \u0026quot;Spectral\u0026quot;, direction = -1, name = \u0026quot;Agency\u0026quot;) + scale_size(name = \u0026quot;Count of Incidents\u0026quot;) + labs(title = sprintf(\u0026quot;Clustering of %s Incidents by LE Stations\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank()) Maybe one more time just for fun!\n Define Crime Description Again crime_des \u0026lt;- \u0026quot;Assault/Simple\u0026quot;  Extract Nested Tibble Again dat \u0026lt;- raleigh_police_nested %\u0026gt;% filter(crime_description == crime_des) %\u0026gt;% .$closest %\u0026gt;% .[[1]] %\u0026gt;% st_as_sf() # Also creating secondary object for density plots dat2 \u0026lt;- raleigh_police %\u0026gt;% filter(crime_description == crime_des) %\u0026gt;% st_coordinates() %\u0026gt;% as_tibble()  Density Plot Again dat2 %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + stat_density_2d(aes(X, Y, fill = ..level..), geom = \u0026quot;polygon\u0026quot;, alpha = 0.6) + viridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) + labs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank())  Hexbin Plot Again dat2 %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + geom_hex(aes(X,Y), alpha = 0.6) + viridis::scale_fill_viridis(option = \u0026quot;magma\u0026quot;, direction = -1, name = \u0026quot;Density\u0026quot;) + labs(title = sprintf(\u0026quot;Density of %s Incidents in Raleigh, NC\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank())  Clustering By Police Stations Again dat %\u0026gt;% st_coordinates() %\u0026gt;% as_tibble() %\u0026gt;% mutate(cnt = dat$cnt, AGENCY = dat$AGENCY) %\u0026gt;% ggplot() + geom_sf(data = raleigh_limits, color = \u0026quot;grey\u0026quot;, fill = NA) + geom_point(aes(X, Y, size = cnt, color = AGENCY), alpha = 0.8) + scale_color_brewer(palette = \u0026quot;Spectral\u0026quot;, direction = -1, name = \u0026quot;Agency\u0026quot;) + scale_size(name = \u0026quot;Count of Incidents\u0026quot;) + labs(title = sprintf(\u0026quot;Clustering of %s Incidents by LE Stations\u0026quot;, crime_des), caption = \u0026quot;Author: Jason Jones \\nSource: http://data-ral.opendata.arcgis.com/\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), plot.title = element_text(size = 14), panel.background = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.line = element_blank()) I really appreciate the class taught by James Cheshire even though this is a little bit of a deviation from clustering to roads. I am thinking something like this could be suited for a shiny application. Not sure if I will ever get around to making that happen.\n ",
    "date": 1542575340,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542575340,
    "objectID": "48b98ee42631e7c4028220e9fafdc4bb",
    "permalink": "/post/2018-11-17-raleigh-police/",
    "publishdate": "2018-11-18T21:09:00Z",
    "relpermalink": "/post/2018-11-17-raleigh-police/",
    "section": "post",
    "summary": "This post was inspired by the MUSA Masterclass provided very graciously by Ken Steif and James Cheshire. If you aren’t familiar with the program I would strongly encourage you to check it out - UPenn MUSA Program.\nI decided to use open data from the City of Raleigh for my exploration. All data can be found on The City of Raleigh’s open data portal. The primary data I am using is contained in the Raleigh Police Incidents (NIBRS) dataset.",
    "tags": null,
    "title": "Spatial Exploration - MUSA Masterclass",
    "type": "post"
  },
  {
    "authors": null,
    "categories": null,
    "content": " library(tidyverse) library(lubridate) bulk_dat \u0026lt;- read_csv(\u0026quot;https://www.dallasopendata.com/api/views/ftja-9jxd/rows.csv\u0026quot;, col_types = cols(offensereportingofficerbadge2 = col_character(), offensebeat = col_character())) %\u0026gt;% mutate(offensedate = as.Date(offensedate, format = \u0026quot;%m/%d/%Y\u0026quot;)) bulk_dat \u0026lt;- bulk_dat %\u0026gt;% mutate(hour = hour(offensetimeofoccurence2)) %\u0026gt;% mutate(age = as.integer(offenseage)) %\u0026gt;% mutate(month = month(offensedate)) bulk_dat %\u0026gt;% ggplot(aes(age)) + geom_histogram(aes(y = ..density..), binwidth = 5, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) + geom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) + geom_vline(aes(xintercept = mean(age, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1) bulk_dat %\u0026gt;% ggplot(aes(hour)) + geom_histogram(aes(y = ..density..), binwidth = 2, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) + geom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) + geom_vline(aes(xintercept = mean(hour, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1) bulk_dat %\u0026gt;% ggplot(aes(month)) + geom_histogram(aes(y = ..density..), binwidth = 1, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) + geom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) + geom_vline(aes(xintercept = mean(month, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1) ",
    "date": 1542056940,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542056940,
    "objectID": "744d2d802d93c9fad3b9182be42a0c37",
    "permalink": "/post/2018-11-12-crime-age-stats/",
    "publishdate": "2018-11-12T21:09:00Z",
    "relpermalink": "/post/2018-11-12-crime-age-stats/",
    "section": "post",
    "summary": "library(tidyverse) library(lubridate) bulk_dat \u0026lt;- read_csv(\u0026quot;https://www.dallasopendata.com/api/views/ftja-9jxd/rows.csv\u0026quot;, col_types = cols(offensereportingofficerbadge2 = col_character(), offensebeat = col_character())) %\u0026gt;% mutate(offensedate = as.Date(offensedate, format = \u0026quot;%m/%d/%Y\u0026quot;)) bulk_dat \u0026lt;- bulk_dat %\u0026gt;% mutate(hour = hour(offensetimeofoccurence2)) %\u0026gt;% mutate(age = as.integer(offenseage)) %\u0026gt;% mutate(month = month(offensedate)) bulk_dat %\u0026gt;% ggplot(aes(age)) + geom_histogram(aes(y = ..density..), binwidth = 5, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;) + geom_density(alpha = .2, fill = \u0026quot;blue\u0026quot;) + geom_vline(aes(xintercept = mean(age, na.rm = TRUE)), color = \u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1) bulk_dat %\u0026gt;% ggplot(aes(hour)) + geom_histogram(aes(y = .",
    "tags": null,
    "title": "Age Is Just A Number…Statistically Speaking",
    "type": "post"
  },
  {
    "authors": null,
    "categories": [
      "R"
    ],
    "content": "  Synopsis In this analysis I amd concerned with two primary points. Which event types have the greatest health impact and the greatest economic impact. I begin my work with data processing to create usable objects for results visualization. I finish my analysis with two plots and a final table.\n Package Load Load packages required for analysis.\nrequire(tidyverse) require(lubridate) require(kableExtra)  Data Import Leveraging read_csv from the readr packackge included with tidyverse to import the dataset.\nweather_dat = read_csv(\u0026quot;data/repdata%2Fdata%2FStormData.csv.bz2\u0026quot;)  Data Processing The first thing I want to do is convert BGN_DATE to a usable longitudinal variable. I am doing this so I can provide change-over-time information as I attempt to answer both questions presented. I am storing the result as a new object so I don’t mess with my original data import object.\nnew_dat = weather_dat %\u0026gt;% mutate(BGN_DATE = str_trim(str_extract(BGN_DATE, \u0026quot;^\\\\S+\\\\s+\u0026quot;))) %\u0026gt;% mutate(BGN_DATE = as.POSIXct(BGN_DATE, format = \u0026quot;%m/%d/%Y\u0026quot;)) I also want to select the most recent ten years of data. Even though there are data points from 1950-01-03 to 2011-11-30, there are a lot of gaps in data collection the farther back you go.\nnew_dat = new_dat %\u0026gt;% filter(year(BGN_DATE) \u0026gt;= (year(max(BGN_DATE)) - 10)) Question 1 Processing I want to attempt to provide my version of an answer to question 1 in three steps. This section will deal with data processing and later I will work through visual creation. The first thing I am doing is creating a fatalities object representative of the top 10 fatality causing event types.\nquest_1_fat = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(fatalities_count = sum(FATALITIES)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, fatalities_count) The next step is to create an injuries object representative of the top 10 injury causing event types. You will notice this step is just a simple modification of the first.\nquest_1_inj = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(injury_count = sum(INJURIES)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, injury_count) The third and final step starts by filtering for event types that are common between quest_1_fat and quest_1_inj, then consolidates data points by month, sums up injuries and fatalities by event type, and then finally gathers injuries and fatalities into one variable.\nquest_1_final = new_dat %\u0026gt;% filter(EVTYPE %in% quest_1_fat$EVTYPE \u0026amp; EVTYPE %in% quest_1_inj$EVTYPE) %\u0026gt;% mutate(BGN_DATE = floor_date(BGN_DATE, unit = \u0026quot;1 month\u0026quot;)) %\u0026gt;% group_by(BGN_DATE, EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;INJURIES\u0026quot;, \u0026quot;FATALITIES\u0026quot;), sum) %\u0026gt;% ungroup() %\u0026gt;% gather(\u0026quot;measure\u0026quot;, \u0026quot;count\u0026quot;, 3:4)  Question 2 Processing To begin question two, I am writing a function to help me convert the character values for thousand, million, and billion to their numeric value as a multiplier for the PROPDMG and CROPDMG variables.\nf = function(dat) { if(dat == \u0026quot;K\u0026quot;) { 1000 } else if (dat == \u0026quot;M\u0026quot;) { 1000000 } else if (dat == \u0026quot;B\u0026quot;) { 1000000000 } else { NA } } Next, I filter out NA values for property and crop damage, create two new variables that replace the character values with integer multipliers, and then calculate actual property and crop damage values.\nnew_dat = new_dat %\u0026gt;% filter(is.na(PROPDMGEXP) == FALSE) %\u0026gt;% filter(is.na(CROPDMGEXP) == FALSE) %\u0026gt;% mutate(prop_mult = as.integer(map_chr(.x = PROPDMGEXP, .f = f))) %\u0026gt;% mutate(crop_mult = as.integer(map_chr(.x = CROPDMGEXP, .f = f))) %\u0026gt;% mutate(prop_dmg = PROPDMG * prop_mult) %\u0026gt;% mutate(crop_dmg = CROPDMG * crop_mult) Very similar to question one, I am now going to look at the top ten event types by total property damage over the last ten years.\nquest_2_prop = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(total_dmg = sum(prop_dmg)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, total_dmg) Here again, I am creating an object that has the top ten event types by total crop damage over the last ten years.\nquest_2_crop = new_dat %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise(total_dmg = sum(crop_dmg)) %\u0026gt;% ungroup() %\u0026gt;% top_n(10, total_dmg) As a final step, I am creating an object that filters for only event types that occur in both top ten lists and then calculates total property and crop damage over time.\nquest_2_final = new_dat %\u0026gt;% filter(EVTYPE %in% quest_2_prop$EVTYPE \u0026amp; EVTYPE %in% quest_2_crop$EVTYPE) %\u0026gt;% mutate(BGN_DATE = floor_date(BGN_DATE, unit = \u0026quot;1 month\u0026quot;)) %\u0026gt;% group_by(BGN_DATE, EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;prop_dmg\u0026quot;, \u0026quot;crop_dmg\u0026quot;), sum) %\u0026gt;% ungroup() %\u0026gt;% gather(\u0026quot;measure\u0026quot;, \u0026quot;total_dmg\u0026quot;, 3:4)   Results Question 1 Results The goal of this plot is to show the most impactful event types over the past ten years. For this, I am using a faceted ggplot column visualization.\nquest_1_final %\u0026gt;% ggplot(aes(as.character(year(BGN_DATE)), count, fill = measure)) + geom_col() + facet_wrap(~EVTYPE, scales = \u0026quot;free_y\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), legend.position = \u0026quot;bottom\u0026quot;, axis.text.x = element_text(angle = 90, vjust = 0.5), axis.title = element_blank(), panel.background = element_blank(), strip.background = element_rect(fill = \u0026quot;#146a90\u0026quot;), strip.text = element_text(color = \u0026quot;white\u0026quot;, face = \u0026quot;bold\u0026quot;)) + scale_fill_viridis_d(\u0026quot;\u0026quot;, direction = -1)  Question 2 Results As with question one, the goal of this plot is to show the most impactful event types over the past ten years in terms of property and crop damage. For this, I am using a faceted ggplot column visualization that is modeled after the question one plot for consistency.\nquest_2_final %\u0026gt;% ggplot(aes(as.character(year(BGN_DATE)), total_dmg/1000000, fill = measure)) + geom_col() + facet_wrap(~EVTYPE, scales = \u0026quot;free_y\u0026quot;) + theme(text = element_text(family = \u0026quot;Roboto\u0026quot;), legend.position = \u0026quot;bottom\u0026quot;, axis.text.x = element_text(angle = 90, vjust = 0.5), axis.title.x = element_blank(), panel.background = element_blank(), strip.background = element_rect(fill = \u0026quot;#146a90\u0026quot;), strip.text = element_text(color = \u0026quot;white\u0026quot;, face = \u0026quot;bold\u0026quot;)) + labs(y = \u0026quot;Total Damage (millions)\u0026quot;) + scale_fill_viridis_d(\u0026quot;\u0026quot;, direction = -1, labels = c(\u0026quot;Crop Damage\u0026quot;, \u0026quot;Property Damage\u0026quot;)) + scale_y_continuous(labels = scales::dollar_format())  Overall What about the worst in terms of economic impact and health? If you look at both question one and two results you will find only one event type consistent between both.\nnew_dat %\u0026gt;% filter(EVTYPE %in% quest_1_fat$EVTYPE \u0026amp; EVTYPE %in% quest_1_inj$EVTYPE \u0026amp; EVTYPE %in% quest_2_prop$EVTYPE \u0026amp; EVTYPE %in% quest_2_crop$EVTYPE) %\u0026gt;% group_by(EVTYPE) %\u0026gt;% summarise_at(c(\u0026quot;INJURIES\u0026quot;, \u0026quot;FATALITIES\u0026quot;, \u0026quot;CROPDMG\u0026quot;, \u0026quot;PROPDMG\u0026quot;), sum) %\u0026gt;% kable(format = \u0026quot;html\u0026quot;, align = \u0026quot;lcccc\u0026quot;, col.names = c(\u0026quot;Event Type\u0026quot;, \u0026quot;Injuries\u0026quot;, \u0026quot;Fatalities\u0026quot;, \u0026quot;Crop Damage\u0026quot;, \u0026quot;Property Damage\u0026quot;), format.args = list(big.mark = \u0026quot;,\u0026quot;)) %\u0026gt;% kable_styling(full_width = TRUE)   Event Type  Injuries  Fatalities  Crop Damage  Property Damage      THUNDERSTORM WIND  1,400  130  66,663  862,257.4       ",
    "date": 1535922540,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1535922540,
    "objectID": "a4a975c6775cf24d6698befa8c0728ae",
    "permalink": "/post/2018-09-02-reproducible-research/",
    "publishdate": "2018-09-02T21:09:00Z",
    "relpermalink": "/post/2018-09-02-reproducible-research/",
    "section": "post",
    "summary": "Synopsis In this analysis I amd concerned with two primary points. Which event types have the greatest health impact and the greatest economic impact. I begin my work with data processing to create usable objects for results visualization. I finish my analysis with two plots and a final table.\n Package Load Load packages required for analysis.\nrequire(tidyverse) require(lubridate) require(kableExtra)  Data Import Leveraging read_csv from the readr packackge included with tidyverse to import the dataset.",
    "tags": [
      "R Markdown",
      "analysis",
      "reproducible"
    ],
    "title": "Health and Economic Impact of Storms and Severe Weather Events",
    "type": "post"
  },
  {
    "authors": [
      "Jason Jones"
    ],
    "categories": null,
    "content": "",
    "date": 1527825600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1527825600,
    "objectID": "f3e51c17dad960210e18ca471df74b94",
    "permalink": "/talk/open-data/",
    "publishdate": "2018-06-01T00:00:00-04:00",
    "relpermalink": "/talk/open-data/",
    "section": "talk",
    "summary": "Talk on the past, present, and future of local government open data given at the 2018 Innovations in Planning for Better Community Housing and Health Symposium at UNCG.",
    "tags": [
      "open data",
      "data"
    ],
    "title": "Government Open Data",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": [
      "R"
    ],
    "content": "  Package Import Load necessary packages and set one global option.\nlibrary(tidyverse) library(pdftools) library(tidytext) library(knitr) library(kableExtra) options(stringsAsFactors = FALSE)  Retrieve File Download the file from the City of Raleigh website, read that file in as a character vector, and delete the downloaded file from the directory.\ndownload.file(\u0026quot;https://www.raleighnc.gov/content/BudgetManagement/Documents/Budget/Archive/2018/FY2018AdoptedBudget20160612.pdf\u0026quot;, \u0026quot;FY2018AdoptedBudget.pdf\u0026quot;, mode = \u0026quot;wb\u0026quot;) txt = pdf_text(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;) unlink(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;)  Create Data Frame Create a page number character vector, create a data frame by binding the page number character vector with the extracted text, and finally “unnest” all of the page text into individual words.\npage = as.character(1:length(txt)) df = data.frame(cbind(page, txt)) budget_words = df %\u0026gt;% unnest_tokens(word, txt)  Cleaning Remove stop words and save as clean object, join sentiment lexicon with clean object, and group the object by page and sentiments before summarising.\ncleaned = budget_words %\u0026gt;% anti_join(stop_words) sentiment = cleaned %\u0026gt;% inner_join(get_sentiments(\u0026quot;nrc\u0026quot;)) sent_count = sentiment %\u0026gt;% group_by(page, sentiment) %\u0026gt;% summarise(sent_count = n()) %\u0026gt;% ungroup() %\u0026gt;% mutate(page = as.integer(page))  Visualize  Negative Word Table   Word  Word Count      APPROPRIATION  77    BONDS  50    DEBT  219    EMERGENCY  67    EXPENDITURE  123    FEE  136    INCOME  65    RISK  31    TAX  153    WASTE  122      Trust Word Table   Word  Word Count      BUDGET  400    CENTER  196    COUNCIL  173    GRANT  85    IMPROVEMENT  93    MANAGEMENT  165    ORDINANCE  88    PLANNING  77    RESOURCES  105    SYSTEM  101      ",
    "date": 1525036140,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1525036140,
    "objectID": "5c491dc7eff91501e4bdcf15639daac9",
    "permalink": "/post/2018-04-29-raleigh-sentiment/",
    "publishdate": "2018-04-29T21:09:00Z",
    "relpermalink": "/post/2018-04-29-raleigh-sentiment/",
    "section": "post",
    "summary": "Package Import Load necessary packages and set one global option.\nlibrary(tidyverse) library(pdftools) library(tidytext) library(knitr) library(kableExtra) options(stringsAsFactors = FALSE)  Retrieve File Download the file from the City of Raleigh website, read that file in as a character vector, and delete the downloaded file from the directory.\ndownload.file(\u0026quot;https://www.raleighnc.gov/content/BudgetManagement/Documents/Budget/Archive/2018/FY2018AdoptedBudget20160612.pdf\u0026quot;, \u0026quot;FY2018AdoptedBudget.pdf\u0026quot;, mode = \u0026quot;wb\u0026quot;) txt = pdf_text(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;) unlink(\u0026quot;FY2018AdoptedBudget.pdf\u0026quot;)  Create Data Frame Create a page number character vector, create a data frame by binding the page number character vector with the extracted text, and finally “unnest” all of the page text into individual words.",
    "tags": [
      "R Markdown",
      "budget",
      "sentiment"
    ],
    "title": "City of Raleigh Budget Sentiment Analysis",
    "type": "post"
  },
  {
    "authors": [
      "Jason Jones"
    ],
    "categories": null,
    "content": "",
    "date": 1515474000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1515474000,
    "objectID": "c91f9fa5241d0f4fa5c8c444fc0484f9",
    "permalink": "/publication/i-have-to-ask-you/",
    "publishdate": "2018-01-09T00:00:00-05:00",
    "relpermalink": "/publication/i-have-to-ask-you/",
    "section": "publication",
    "summary": "Apparently ELGL co-founder Kent Wyatt moonlights as a private background investigator, diving deep into the past lives of all of his ELGL family. Sometimes I forget that I spent five years as a track and field athlete while also receiving a quality education at North Carolina State University. I mean, it isn’t really something that you whip out of your “fun facts bag” all that frequently. Discussing the intricate physics of spinning in a circle with a sixteen pound cast iron ball before releasing it in a blur of chalk dust and grunting doesn’t make for the best dinner conversation.",
    "tags": [
      "ELGL"
    ],
    "title": "I Have to Ask You",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1461729600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1461729600,
    "objectID": "d1311ddf745551c9e117aa4bb7e28516",
    "permalink": "/project/external-project/",
    "publishdate": "2016-04-27T00:00:00-04:00",
    "relpermalink": "/project/external-project/",
    "section": "project",
    "summary": "An example of linking directly to an external project website using `external_link`.",
    "tags": [
      "Demo"
    ],
    "title": "External Project",
    "type": "project"
  },
  {
    "authors": null,
    "categories": null,
    "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n",
    "date": 1461729600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1461729600,
    "objectID": "8f66d660a9a2edc2d08e68cc30f701f7",
    "permalink": "/project/internal-project/",
    "publishdate": "2016-04-27T00:00:00-04:00",
    "relpermalink": "/project/internal-project/",
    "section": "project",
    "summary": "An example of using the in-built project page.",
    "tags": [
      "Deep Learning"
    ],
    "title": "Internal Project",
    "type": "project"
  },
  {
    "authors": null,
    "categories": null,
    "content": " Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n",
    "date": -62135596800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": -62135596800,
    "objectID": "c2915ec5da95791851caafdcba9664af",
    "permalink": "/slides/example-slides/",
    "publishdate": "0001-01-01T00:00:00Z",
    "relpermalink": "/slides/example-slides/",
    "section": "slides",
    "summary": "Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$",
    "tags": null,
    "title": "Slides",
    "type": "slides"
  }
]